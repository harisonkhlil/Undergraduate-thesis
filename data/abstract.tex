%%================================================
%% Filename: abstract.tex
%% Encoding: UTF-8
%% Author: Yuan Xiaoshuai - yxshuai@gmail.com
%% Created: 2012-04-24 00:21
%% Last modified: 2019-11-01 09:26
%%================================================
\begin{cabstract}

互联网的发展迅速，且携带的信息量巨大，信息交流速度迅速，自由程度高，并且实现了全球的信息共享。
但同时用户增加导致访问量暴增，很大成程度上增加了网络服务器的压力，同时也对服务器的性能提出了更高的要求。
由于大量的 Web 高并发访问对后台的服务器造成的压力问题亟待解决。
由此应运而生的服务器集群系统和负载均衡技术很大程度上缓解了这个问题，
并且这些技术一方面改善了服务器的性能，另一方面很大幅度地缩减了改善服务器性能所需要的开销。
现在服务器上应用的负载均衡技术有很多，有的分配策略也存在不足，可能会影响繁忙的服务器处理任务的同时还接收着大量访问请求，
而部分服务器却处于空闲状态未分配到请求任务，这种现象会影响整个服务器集群对高并发访问的响应速度，使得用户体验变差。

针对服务器集群中负载均衡策略存在的分配不合理问题，本文研究了基于 Nginx 高并发服务器的负载均衡算法，其主要工作如下：

基于对 Nginx 高并发访问的研究，我发现了现有的 Nginx 服务器针对加权轮询算法负载分配不够合理。
根据已经学习的机器学习和深度学习方法，利用时间序列预测算法对网络用户请求量进行预测。
提出了改进的动态负载均衡算法对用户的请求任务进行分配，采用对节点的剩余性能预测结果判断是否调整当前的负载均衡方案。
参考 TCP 拥塞控制原理，来对服务器节点的权重进行调整，从而达到控制节点负载状态的目的，并使用虚拟机或云服务器搭建 Linux 服务器集群系统，进行负载均衡算法实验的分析

\end{cabstract}

\ckeywords{Nginx, 服务器集群, 负载均衡, 高并发, 时间序列算法}

\begin{eabstract} 
The rapid development of the internet carries a huge amount of information, 
exchanging information at high speed with a high degree of freedom, and has achieved global information sharing.
However, the increase in users has led to an explosion in access volume, 
which to a large extent has increased the pressure on network servers, and also put higher demands on server performance.
The problem of the stress caused by a large amount of high-concurrency Web accesses to the backend servers urgently needs to be resolved. 
Born from this are server cluster systems and load balancing technologies that have to a large degree alleviated this issue. 
These technologies have on the one hand improved server performance, and on the other hand massively reduced the overhead needed to improve server performance. 
Various load balancing technologies are now applied on servers, some of which may be imperfect in their distribution strategies, 
possibly leading to busy servers still receiving many access requests while dealing with tasks, 
while some servers are idle and do not get assigned task requests. 
This phenomenon affects the response speed of the entire server cluster to high-concurrency access, 
making the user experience worse.

To deal with the problem of improper distribution in load balancing strategies within server clusters, 
this paper has studied the load balancing algorithm based on the Nginx high-concurrency server.
Its main work is as follows:

Based on research on high-concurrency access to Nginx,
I found that the load distribution of the existing Nginx server for the weighted round robin algorithm is not reasonable enough.
According to the machine learning and deep learning methods I have learned, 
I used time series prediction algorithms to predict the volume of network user requests.
I proposed an improved dynamic load balancing algorithm for assigning user request tasks and decided whether to adjust the current load balancing plan based on the results of predicting the residual performance of the nodes.
Reference was made to TCP congestion control principles to adjust the weight of the server nodes.
This achieves the aim of controlling node load states,
and uses virtual machines or cloud servers to build a Linux server cluster system for the analysis of load balancing algorithm experiments.
\end{eabstract}

\ekeywords{Nginx, Server Clusters, Load Balancing, High-Concurrency, Time Series Algorithms}
